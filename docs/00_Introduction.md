---
title: 这是一个机器学习笔记
author: 程俊彦
date: 2022-10-29
---
[TOC]
## PAC（Probably Approximately Correct）学习框架

我们拥有样本集合$\mathcal{X}$，标签集合$\mathcal{Y}$，$c\in\mathcal{C}$,$c$表示从$\mathcal{X}$到$\mathcal{Y}$的一个映射，称为概念，$\mathcal{C}$是概念的集合，称为概念类，是我们**希望想要学习的**映射。而$\mathcal{H}$表示所有的概念类（上帝预设的映射）。我们观测到的是样本$T=\left\{(X_1,Y_1),(X_2,Y_2),\cdots,(X_n,Y_n)\right\}$,但我们学习到的是$S=\left\{(X_1,C(Y_1)),(X_2,C(Y_2)),\cdots,(X_n,C(Y_n))\right\}$,那么学习器任务就是利用S取找到一个假设$h_s\in\mathcal{H}$,使其对于目标概念c有尽可能小的泛化误差，假设$h\in\mathcal{H}$的**泛化误差**记为:
$$R(h)=\mathcal{Pr}_{x\sim D}[h(x)\neq c(x)]=\mathbf{E}_{x\sim D}[I_{h(x)\neq c(x)}]$$
明确泛化误差往往不可知，因为分布D和目标概念都是不可得的，所以学习器度量的是在有标签样本集上的**经验误差**:
$$
\hat{R(h)=\frac{1}{m}\sum\limits_{i=1}\limits^mI_{h(x_i)\neq c(x_i)}}
$$
如果样本集是i.i.d.的，那么经验误差就等于泛化误差,$E[\hat{R(h)}]=R(h)$
到此正式引出概率近似正确的概念，对概念$c\in\mathcal{C}$计算表示的最大代价记为$size(c)$
**PAC学习**：如果存在一个算法$\mathcal{A}$以及一个多项式算法$pol
y(1/\epsilon, 1/\delta, n, size(c))$（指的是存在一个具有多项式复杂度的学习算法，而不是指多项式模型！）使得对于任意$\epsilon >0$以及$\delta >0$，对于所有在$\mathcal{X}$上的分布D和任意目标概念$c\in\mathcal{C}$，对于满足$m>poly(1/\epsilon, 1/\delta, n, size(c))$的任意样本规模m均有下式成立，那么概念类$\mathcal{C}$是PAC可学习的：
$$
\mathcal{Pr}_{s\sim D^m}[R(h_s)\leq \epsilon]\geq 1-\delta
$$

## 一、基本定义
### 1、三要素

方法 = 模型 + 策略 + 算法 
- 模型：生成或者判别
- 策略：损失函数
- 算法：求解方法
### 2、召回率，精确率及F1指数

1. 精确率：预测为真的总体中，实际值为真的比例。$\frac{TP}{TP+FP}$
2. 召回率：在实际为真的总体中，预测为真的比例。$\frac{TP}{TP+FN}$ 
3. F1 是召回率和精确率的调和平均数。
    1. 灵敏度TPR（真阳率，召回率）
    2. 特异度FPR（假阳率）识别的假阳例占所有负例的比例。
        1. ROC曲线直观上，TPR 代表能将正例分对的概率，FPR 代表将负例错分为正例的概率。在 ROC 空间中，每个点的横坐标是 FPR，纵坐标是 TPR，这也就描绘了分类器在 TP（真正率）和 FP（假正率）间的 trade-off2。
        2. AUC（Area Under Curve）被定义为ROC曲线下的面积，显然这个面积的数值不会大于1。翻译过来就是，随机挑选一个正样本以及一个负样本，分类器判定正样本的值高于负样本的概率就是 AUC 值。
           - 简单说：AUC值越大的分类器，正确率越高。
           - AUC=1，完美分类器，采用这个预测模型时，不管设定什么阈值都能得出完美预测。绝大多数预测的场合，不存在完美分类器。
           - 0.5<AUC<1，优于随机猜测。这个分类器（模型）妥善设定阈值的话，能有预测价值。
           - AUC=0.5，跟随机猜测一样（例：丢铜板），模型没有预测价值。
           - AUC<0.5，比随机猜测还差；但只要总是反预测而行，就优于随机猜测，因此不存在 AUC<0.5 的情况。
### 3、经验风险最小化、结构风险最小化与正则化

- 当样本容量很小时, 经验风险最小化学习的效果就末必很好, 会产生 “过拟合” (over-fitting) 现象。  
- 结构风险最小化 (structural risk minimization, SRM) 是为了防止过拟合而提出 来的策略。结构风险最小化等价于正则化 (regularization)。结构风险在经验风险上加 上表示模型复杂度的正则化项 (regularizer) 或罚项 (penalty term)。在假设空间、损 失函数以及训练数据集确定的情况下，结构风险的定义是：
$$
R_{\mathrm{srm}}(f)=\frac{1}{N} \sum_{i=1}^N L\left(y_i, f\left(x_i\right)\right)+\lambda J(f)
$$
其中 $J(f)$ 为模型的复杂度, 是定义在假设空间 $\mathcal{F}$ 上的泛函。模型 $f$ 越复杂, 复杂度 $J(f)$ 就越大; 反之, 模型 $f$ 越简单, 复杂度 $J(f)$ 就越小。也就是说, 复杂度表示了对 复杂模型的惩罚。 $\lambda \geqslant 0$ 是系数, 用以权衡经验风险和模型复杂度。结构风险小需要经 验风险与模型复杂度同时小。结构风险小的模型往往对训练数据以及末知的测试数据 都有较好的预测。
- 比如, 贝叶斯估计中的最大后验概率估计 (maximum posterior probability estimation, MAP) 就是结构风险最小化的一个例子。当模型是条件概率分布、损失函数 是对数损失函数、模型复杂度由模型的先验概率表示时, 结构风险最小化就等价于最 大后验概率估计。结构风险最小化的策略认为结构风险最小的模型是最优的模型。所以求最优模 型, 就是求解最优化问题:
$$
\min _{f \in \mathcal{F}} \frac{1}{N} \sum_{i=1}^N L\left(y_i, f\left(x_i\right)\right)+\lambda J(f)
$$
### 4、交叉验证

数据分为：测试集，验证集和训练集
- 简单交叉验证
  七三开数据，七成训练，三成测试，选择最优
- S折交叉验证
  S分数据，数据不相交，S-1用于训练，剩下的一个用于测试，用完所有排列组合$C^{1}_{s}$
- 留一交叉验证
  令S=N

### 5、机器学习思路
![机器学习思路图](images/2022-11-03-11-11-57.png)
- 但是对我来说，只有自己先编程源码，才能更好的理解调包的内容，我选12453。
### 参考文献
> [知乎-月来客栈](https://zhuanlan.zhihu.com/p/123914015)